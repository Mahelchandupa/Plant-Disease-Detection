# -*- coding: utf-8 -*-
"""Plant Disease Detection Final .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1E4aJIbfLCrlwIQZddZXb8nACs073ivhp
"""

# PLANT DISEASE DETECTION PROJECT
# Student: R.A.M.C. Ranaweera
# Course: Computer Vision
# Objective: Compare CNN vs Transfer Learning for tomato disease classification

from google.colab import drive
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import cv2
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D
from tensorflow.keras.applications import ResNet50V2, VGG16
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Connect to Google Drive to access dataset
drive.mount('/content/drive')

print("TensorFlow version:", tf.__version__)
print("GPU available:", len(tf.config.list_physical_devices('GPU')) > 0)

# Set random seeds to ensure reproducible results
tf.random.set_seed(42)
np.random.seed(42)

# =====================================================
# STEP 1: DATA LOADING AND PREPROCESSING
# =====================================================

def load_working_dataset():
    """
    Load tomato leaf images from PlantVillage dataset
    Focus on 4 classes that are most different from each other
    """

    # Path to the dataset in Google Drive
    data_dir = '/content/drive/MyDrive/Datasets/PlantVillage/plantvillage dataset/color'

    # Selected 4 disease classes for classification
    # Chose these because they have distinct visual patterns
    selected_classes = [
        'Tomato___healthy',           # Normal healthy leaves
        'Tomato___Early_blight',      # Dark spots with rings
        'Tomato___Late_blight',       # Brown irregular patches
        'Tomato___Bacterial_spot'     # Small dark circular spots
    ]

    print(f"Loading dataset with {len(selected_classes)} classes...")

    images = []
    labels = []
    class_counts = {}

    # Process each disease class
    for class_idx, class_name in enumerate(selected_classes):
        class_path = os.path.join(data_dir, class_name)

        if not os.path.exists(class_path):
            print(f"Warning: {class_path} not found")
            continue

        # Get all image files in this class folder
        image_files = [f for f in os.listdir(class_path)
                      if f.lower().endswith(('.jpg', '.jpeg', '.png'))]

        # Limit to 200 images per class to keep dataset manageable
        # More images = better training but longer processing time
        max_images = min(len(image_files), 200)
        image_files = image_files[:max_images]

        print(f"Loading {len(image_files)} images from {class_name}")

        # Process each image in this class
        for img_file in image_files:
            img_path = os.path.join(class_path, img_file)
            try:
                # Read image using OpenCV
                img = cv2.imread(img_path)
                if img is None:
                    continue

                # Convert from BGR to RGB (important for correct colors)
                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

                # Resize all images to same size (128x128)
                # This is required because neural networks need consistent input size
                img = cv2.resize(img, (128, 128))

                # Normalize pixel values from 0-255 to 0-1
                # This helps neural networks train better
                img = img.astype(np.float32) / 255.0

                images.append(img)
                labels.append(class_idx) # Convert class name to number

            except Exception as e:
                continue # Skip corrupted images

        class_counts[class_name] = len([l for l in labels if l == class_idx])

    # Convert lists to numpy arrays for neural network training
    X = np.array(images)
    y = to_categorical(labels, num_classes=len(selected_classes)) # One-hot encoding

    print(f"\nDataset loaded successfully:")
    print(f"  Total images: {X.shape[0]}")
    print(f"  Image shape: {X.shape[1:]}")
    print(f"  Classes: {len(selected_classes)}")
    print(f"  Class distribution: {class_counts}")

    return X, y, selected_classes, class_counts

# Load the preprocessed dataset
X, y, class_names, class_counts = load_working_dataset()

# Split data into training and validation sets (80% train, 20% validation)
# Stratify ensures each class has proportional representation in both sets
X_train, X_val, y_train, y_val = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=np.argmax(y, axis=1)
)

print(f"\nData split:")
print(f"  Train: {X_train.shape[0]} images")
print(f"  Validation: {X_val.shape[0]} images")

# =====================================================
# VISUALIZATION FUNCTIONS (For Report)
# =====================================================

def show_sample_images():
    """Generate dataset_samples.png"""
    plt.figure(figsize=(20, 12))

    samples_per_class = 6
    for class_idx, class_name in enumerate(class_names):
        # Get images from this specific class
        class_mask = np.argmax(y_train, axis=1) == class_idx
        class_images = X_train[class_mask]

        # Display 6 sample images per class
        for i in range(samples_per_class):
            plt.subplot(len(class_names), samples_per_class, class_idx * samples_per_class + i + 1)
            if i < len(class_images):
                plt.imshow(class_images[i])
                if i == 0: # Label only the first image of each row
                    clean_name = class_name.split('___')[1].replace('_', ' ')
                    plt.ylabel(clean_name, fontsize=14, fontweight='bold')
                plt.title(f'Sample {i+1}', fontsize=10)
            plt.axis('off')

    plt.suptitle('Dataset Sample Images - Each Class', fontsize=18, fontweight='bold', y=0.98)
    plt.tight_layout()
    # Save for use in final report
    plt.savefig('/content/drive/MyDrive/Datasets/PlantVillage/dataset_samples.png',
                dpi=300, bbox_inches='tight')
    plt.show()
    plt.close()

def show_class_distribution():
    """Create charts showing how many images we have per class"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))

    # Count images in training and validation sets for each class
    train_counts = {}
    val_counts = {}

    for i, class_name in enumerate(class_names):
        train_mask = np.argmax(y_train, axis=1) == i
        val_mask = np.argmax(y_val, axis=1) == i
        clean_name = class_name.split('___')[1].replace('_', ' ')
        train_counts[clean_name] = np.sum(train_mask)
        val_counts[clean_name] = np.sum(val_mask)

    # Chart 1: Training data distribution
    bars1 = ax1.bar(train_counts.keys(), train_counts.values(),
                    color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4'], alpha=0.8)
    ax1.set_title('Training Data Distribution', fontsize=14, fontweight='bold')
    ax1.set_ylabel('Number of Images', fontsize=12)
    ax1.tick_params(axis='x', rotation=45)

    # Add numbers on top of bars
    for bar in bars1:
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2., height + 2,
                f'{int(height)}', ha='center', va='bottom', fontweight='bold')

    # Chart 2: Train vs Validation comparison
    x = np.arange(len(class_names))
    width = 0.35

    clean_names = [name.split('___')[1].replace('_', ' ') for name in class_names]
    bars2 = ax2.bar(x - width/2, list(train_counts.values()), width,
                    label='Training', alpha=0.8, color='skyblue')
    bars3 = ax2.bar(x + width/2, list(val_counts.values()), width,
                    label='Validation', alpha=0.8, color='lightcoral')

    ax2.set_title('Train vs Validation Split', fontsize=14, fontweight='bold')
    ax2.set_ylabel('Number of Images', fontsize=12)
    ax2.set_xticks(x)
    ax2.set_xticklabels(clean_names, rotation=45)
    ax2.legend()

    # Add numbers on bars
    for bars in [bars2, bars3]:
        for bar in bars:
            height = bar.get_height()
            ax2.text(bar.get_x() + bar.get_width()/2., height + 1,
                    f'{int(height)}', ha='center', va='bottom', fontsize=9, fontweight='bold')

    plt.tight_layout()
    plt.savefig('/content/drive/MyDrive/Datasets/PlantVillage/class_distribution.png',
                dpi=300, bbox_inches='tight')
    plt.show()
    plt.close()

# Generate visualizations for the report
show_sample_images()
show_class_distribution()

# =====================================================
# STEP 2: MODEL ARCHITECTURES
# =====================================================

def create_working_cnn():
    """
    Build a custom CNN from scratch
    Architecture: 4 convolutional blocks + 2 dense layers
    Uses batch normalization and dropout to prevent overfitting
    """
    model = Sequential([
        # First convolutional block - detects basic edges and shapes
        Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),
        BatchNormalization(),  # Normalizes inputs to speed up training
        MaxPooling2D(2, 2),    # Reduces image size by half
        Dropout(0.25),         # Randomly removes 25% of connections to prevent overfitting

        # Second block - detects more complex patterns
        Conv2D(64, (3, 3), activation='relu'),
        BatchNormalization(),
        MaxPooling2D(2, 2),
        Dropout(0.25),

        # Third block - detects disease-specific features
        Conv2D(128, (3, 3), activation='relu'),
        BatchNormalization(),
        MaxPooling2D(2, 2),
        Dropout(0.25),

        # Fourth block - high-level feature extraction
        Conv2D(256, (3, 3), activation='relu'),
        BatchNormalization(),
        GlobalAveragePooling2D(),  # Better than Flatten - reduces overfitting
        Dropout(0.5),

        # Classification layers
        Dense(512, activation='relu'),  # Hidden layer for complex combinations
        BatchNormalization(),
        Dropout(0.5),
        Dense(len(class_names), activation='softmax')  # Output layer - 4 classes
    ])

    return model

def create_working_transfer():
    """
    Build transfer learning model using pre-trained VGG16
    VGG16 was trained on ImageNet (millions of images)
    We use its learned features and adapt them for plant diseases
    """

    # Load VGG16 pre-trained on ImageNet, without top classification layers
    base_model = VGG16(
        weights='imagenet',      # Use pre-trained weights
        include_top=False,       # Remove final classification layers
        input_shape=(128, 128, 3)
    )

    # Freeze most layers to keep learned features
    # Only allow last 4 layers to train (fine-tuning)
    for layer in base_model.layers[:-4]:
        layer.trainable = False

    # Add a custom classification layers on top
    model = Sequential([
        base_model,              # Pre-trained feature extractor
        GlobalAveragePooling2D(), # Converts feature maps to vector
        BatchNormalization(),
        Dropout(0.3),            # Less dropout since pre-trained features are robust
        Dense(512, activation='relu'),
        BatchNormalization(),
        Dropout(0.4),
        Dense(256, activation='relu'),
        Dropout(0.3),
        Dense(len(class_names), activation='softmax')  # 4 disease classes
    ])

    return model

# Create both models for comparison
print("Creating models...")

# Model 1: Custom CNN built from scratch
working_cnn = create_working_cnn()
working_cnn.compile(
    optimizer=Adam(learning_rate=0.001),  # Learning rate for CNN
    loss='categorical_crossentropy',       # Standard loss for multi-class classification
    metrics=['accuracy']
)

# Model 2: Transfer learning with VGG16
working_transfer = create_working_transfer()
working_transfer.compile(
    optimizer=Adam(learning_rate=0.0001),  # Lower learning rate for transfer learning
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

print("Models created successfully:")
print(f"Working CNN parameters: {working_cnn.count_params():,}")
print(f"Working Transfer parameters: {working_transfer.count_params():,}")

# Show the CNN architecture
working_cnn.summary()

# =====================================================
# STEP 3: DATA AUGMENTATION AND TRAINING SETUP
# =====================================================

# Data augmentation - artificially increase dataset size by transforming images
# This helps prevent overfitting and makes models more robust
train_datagen = ImageDataGenerator(
    rotation_range=15,        # Rotate images up to 15 degrees
    width_shift_range=0.1,    # Shift horizontally by 10%
    height_shift_range=0.1,   # Shift vertically by 10%
    zoom_range=0.1,           # Zoom in/out by 10%
    horizontal_flip=True,     # Flip images left-right (leaves can be oriented either way)
    fill_mode='nearest'       # Fill empty pixels with nearest neighbor
)

# No augmentation for validation - we want consistent evaluation
val_datagen = ImageDataGenerator()

# Training configuration
EPOCHS = 25        # Maximum number of training cycles
BATCH_SIZE = 32    # Number of images processed at once

print(f"\nTraining Configuration:")
print(f"  Epochs: {EPOCHS}")
print(f"  Batch Size: {BATCH_SIZE}")
print(f"  Training Images: {len(X_train)}")
print(f"  Validation Images: {len(X_val)}")

# Callbacks to improve training
callbacks = [
    # Stop training early if validation accuracy stops improving
    EarlyStopping(
        monitor='val_accuracy',
        patience=7,              # Wait 7 epochs before stopping
        restore_best_weights=True,
        verbose=1
    ),
    # Reduce learning rate when validation accuracy plateaus
    ReduceLROnPlateau(
        monitor='val_accuracy',
        factor=0.2,              # Multiply learning rate by 0.2
        patience=4,
        min_lr=1e-7,
        verbose=1
    ),
    # Save the best model during training
    ModelCheckpoint(
        '/content/drive/MyDrive/Datasets/PlantVillage/best_working_model.keras',
        monitor='val_accuracy',
        save_best_only=True,
        verbose=1
    )
]

# =====================================================
# STEP 4: TRAIN BOTH MODELS
# =====================================================

print("\n" + "="*70)
print("TRAINING CUSTOM CNN")
print("="*70)

# Train the custom CNN
history_cnn = working_cnn.fit(
    train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),
    steps_per_epoch=len(X_train) // BATCH_SIZE,  # How many batches per epoch
    epochs=EPOCHS,
    validation_data=(X_val, y_val),
    callbacks=callbacks,
    verbose=1
)

print(f"CNN Training completed!")
print(f"Best validation accuracy: {max(history_cnn.history['val_accuracy']):.4f}")

print("\n" + "="*70)
print("TRAINING TRANSFER LEARNING MODEL")
print("="*70)

# Train the transfer learning model
history_transfer = working_transfer.fit(
    train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),
    steps_per_epoch=len(X_train) // BATCH_SIZE,
    epochs=EPOCHS,
    validation_data=(X_val, y_val),
    callbacks=callbacks,
    verbose=1
)

print(f"Transfer Learning completed!")
print(f"Best validation accuracy: {max(history_transfer.history['val_accuracy']):.4f}")

# =====================================================
# VISUALIZATION: TRAINING HISTORY
# =====================================================

def show_training_history():
    """Generate training_history.png"""
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))

    # Plot 1: Accuracy
    axes[0, 0].plot(history_cnn.history['accuracy'], label='CNN Train', linewidth=2, color='blue')
    axes[0, 0].plot(history_cnn.history['val_accuracy'], label='CNN Val', linewidth=2, color='blue', linestyle='--')
    axes[0, 0].plot(history_transfer.history['accuracy'], label='Transfer Train', linewidth=2, color='red')
    axes[0, 0].plot(history_transfer.history['val_accuracy'], label='Transfer Val', linewidth=2, color='red', linestyle='--')
    axes[0, 0].set_title('Model Accuracy Over Time', fontsize=14, fontweight='bold')
    axes[0, 0].set_xlabel('Epoch')
    axes[0, 0].set_ylabel('Accuracy')
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)

    # Plot 2: Loss
    axes[0, 1].plot(history_cnn.history['loss'], label='CNN Train', linewidth=2, color='blue')
    axes[0, 1].plot(history_cnn.history['val_loss'], label='CNN Val', linewidth=2, color='blue', linestyle='--')
    axes[0, 1].plot(history_transfer.history['loss'], label='Transfer Train', linewidth=2, color='red')
    axes[0, 1].plot(history_transfer.history['val_loss'], label='Transfer Val', linewidth=2, color='red', linestyle='--')
    axes[0, 1].set_title('Model Loss Over Time', fontsize=14, fontweight='bold')
    axes[0, 1].set_xlabel('Epoch')
    axes[0, 1].set_ylabel('Loss')
    axes[0, 1].legend()
    axes[0, 1].grid(True, alpha=0.3)

    # Plot 3: Final Accuracy
    final_accs = [
        max(history_cnn.history['val_accuracy']),
        max(history_transfer.history['val_accuracy'])
    ]
    model_names = ['Working CNN', 'Working Transfer']
    bars = axes[1, 0].bar(model_names, final_accs, color=['skyblue', 'lightcoral'], alpha=0.8)
    axes[1, 0].set_title('Final Validation Accuracy', fontsize=14, fontweight='bold')
    axes[1, 0].set_ylabel('Accuracy')
    axes[1, 0].set_ylim(0, 1)

    for bar, acc in zip(bars, final_accs):
        axes[1, 0].text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.01,
                       f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')

    # Plot 4: Improvement over original
    original_accs = [0.3625, 0.2500]  # Original results
    current_accs = final_accs

    x_pos = np.arange(2)
    width = 0.35

    bars1 = axes[1, 1].bar(x_pos - width/2, original_accs, width,
                           label='Original Models', alpha=0.8, color='red')
    bars2 = axes[1, 1].bar(x_pos + width/2, current_accs, width,
                           label='Working Models', alpha=0.8, color='green')

    axes[1, 1].set_title('Accuracy Improvement', fontsize=14, fontweight='bold')
    axes[1, 1].set_ylabel('Accuracy')
    axes[1, 1].set_xticks(x_pos)
    axes[1, 1].set_xticklabels(['CNN', 'Transfer'])
    axes[1, 1].legend()
    axes[1, 1].axhline(y=0.6, color='blue', linestyle='--', alpha=0.7, label='60% Target')

    for bars in [bars1, bars2]:
        for bar in bars:
            height = bar.get_height()
            axes[1, 1].text(bar.get_x() + bar.get_width()/2., height + 0.01,
                           f'{height:.1%}', ha='center', va='bottom', fontweight='bold')

    plt.tight_layout()
    plt.savefig('/content/drive/MyDrive/Datasets/PlantVillage/training_history.png',
                dpi=300, bbox_inches='tight')
    plt.show()
    plt.close()

show_training_history()

# =====================================================
# STEP 5: EVALUATION WITH ALL VISUALIZATIONS
# =====================================================

def evaluate_model_comprehensive(model, X_val, y_val, class_names, model_name):
    """Comprehensive evaluation with all metrics"""
    print(f"\n{'='*70}")
    print(f"EVALUATING {model_name}")
    print(f"{'='*70}")

    predictions = model.predict(X_val, verbose=0)
    y_pred = np.argmax(predictions, axis=1)
    y_true = np.argmax(y_val, axis=1)

    accuracy = accuracy_score(y_true, y_pred)
    report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)

    print(f"Final Accuracy: {accuracy:.4f} ({accuracy*100:.1f}%)")
    print(f"Macro Precision: {report['macro avg']['precision']:.4f}")
    print(f"Macro Recall: {report['macro avg']['recall']:.4f}")
    print(f"Macro F1-Score: {report['macro avg']['f1-score']:.4f}")

    print(f"\nPer-Class Performance:")
    for class_name in class_names:
        if class_name in report:
            metrics = report[class_name]
            clean_name = class_name.split('___')[1]
            print(f"  {clean_name:15}: Precision={metrics['precision']:.3f}, "
                  f"Recall={metrics['recall']:.3f}, F1={metrics['f1-score']:.3f}")

    print(f"\nDetailed Classification Report:")
    clean_names = [name.split('___')[1] for name in class_names]
    print(classification_report(y_true, y_pred, target_names=clean_names))

    return {
        'accuracy': accuracy,
        'precision': report['macro avg']['precision'],
        'recall': report['macro avg']['recall'],
        'f1_score': report['macro avg']['f1-score'],
        'predictions': predictions,
        'y_pred': y_pred,
        'y_true': y_true
    }

# Evaluate both models
cnn_results = evaluate_model_comprehensive(working_cnn, X_val, y_val, class_names, "Working CNN")
transfer_results = evaluate_model_comprehensive(working_transfer, X_val, y_val, class_names, "Working Transfer Learning")

# =====================================================
# VISUALIZATION: CONFUSION MATRICES
# =====================================================

def show_confusion_matrices():
    """Generate confusion_matrices.png"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))

    clean_names = [name.split('___')[1].replace('_', ' ') for name in class_names]

    cm_cnn = confusion_matrix(cnn_results['y_true'], cnn_results['y_pred'])
    sns.heatmap(cm_cnn, annot=True, fmt='d', cmap='Blues',
                xticklabels=clean_names, yticklabels=clean_names, ax=ax1)
    ax1.set_title('Working CNN - Confusion Matrix', fontsize=14, fontweight='bold')
    ax1.set_ylabel('True Label', fontsize=12)
    ax1.set_xlabel('Predicted Label', fontsize=12)

    cm_transfer = confusion_matrix(transfer_results['y_true'], transfer_results['y_pred'])
    sns.heatmap(cm_transfer, annot=True, fmt='d', cmap='Reds',
                xticklabels=clean_names, yticklabels=clean_names, ax=ax2)
    ax2.set_title('Working Transfer Learning - Confusion Matrix', fontsize=14, fontweight='bold')
    ax2.set_ylabel('True Label', fontsize=12)
    ax2.set_xlabel('Predicted Label', fontsize=12)

    plt.tight_layout()
    plt.savefig('/content/drive/MyDrive/Datasets/PlantVillage/confusion_matrices.png',
                dpi=300, bbox_inches='tight')
    plt.show()
    plt.close()

show_confusion_matrices()

# =====================================================
# VISUALIZATION: PERFORMANCE COMPARISON
# =====================================================

def show_performance_comparison():
    """Generate performance_comparison.png"""
    comparison_df = pd.DataFrame({
        'Working CNN': [
            cnn_results['accuracy'],
            cnn_results['precision'],
            cnn_results['recall'],
            cnn_results['f1_score']
        ],
        'Working Transfer Learning': [
            transfer_results['accuracy'],
            transfer_results['precision'],
            transfer_results['recall'],
            transfer_results['f1_score']
        ]
    }, index=['Accuracy', 'Precision', 'Recall', 'F1-Score'])

    fig, axes = plt.subplots(2, 2, figsize=(16, 12))

    # Plot 1: Metrics Comparison
    x = np.arange(len(comparison_df.index))
    width = 0.35
    bars1 = axes[0, 0].bar(x - width/2, comparison_df['Working CNN'], width,
                           label='Working CNN', alpha=0.8, color='skyblue')
    bars2 = axes[0, 0].bar(x + width/2, comparison_df['Working Transfer Learning'], width,
                           label='Working Transfer Learning', alpha=0.8, color='lightcoral')
    axes[0, 0].set_title('Performance Metrics Comparison', fontsize=14, fontweight='bold')
    axes[0, 0].set_xlabel('Metrics')
    axes[0, 0].set_ylabel('Score')
    axes[0, 0].set_xticks(x)
    axes[0, 0].set_xticklabels(comparison_df.index)
    axes[0, 0].legend()
    axes[0, 0].grid(axis='y', alpha=0.3)

    for bars in [bars1, bars2]:
        for bar in bars:
            height = bar.get_height()
            axes[0, 0].text(bar.get_x() + bar.get_width()/2., height + 0.01,
                           f'{height:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=9)

    # Plot 2: Improvement Analysis
    original_accs = [0.3625, 0.2500]
    current_accs = [cnn_results['accuracy'], transfer_results['accuracy']]

    x_pos = np.arange(2)
    width = 0.35

    bars3 = axes[0, 1].bar(x_pos - width/2, original_accs, width,
                           label='Original Models', alpha=0.8, color='red')
    bars4 = axes[0, 1].bar(x_pos + width/2, current_accs, width,
                           label='Working Models', alpha=0.8, color='green')

    axes[0, 1].set_title('Accuracy Improvement', fontsize=14, fontweight='bold')
    axes[0, 1].set_ylabel('Accuracy')
    axes[0, 1].set_xticks(x_pos)
    axes[0, 1].set_xticklabels(['CNN', 'Transfer Learning'])
    axes[0, 1].legend()
    axes[0, 1].axhline(y=0.6, color='blue', linestyle='--', alpha=0.7, label='60% Target')

    for bars in [bars3, bars4]:
        for bar in bars:
            height = bar.get_height()
            axes[0, 1].text(bar.get_x() + bar.get_width()/2., height + 0.01,
                           f'{height:.1%}', ha='center', va='bottom', fontweight='bold')

    # Plot 3: Per-Class F1 Scores
    clean_names = [name.split('___')[1].replace('_', ' ') for name in class_names]

    cnn_f1_per_class = []
    transfer_f1_per_class = []

    cnn_report = classification_report(cnn_results['y_true'], cnn_results['y_pred'],
                                       target_names=class_names, output_dict=True)
    transfer_report = classification_report(transfer_results['y_true'], transfer_results['y_pred'],
                                            target_names=class_names, output_dict=True)

    for class_name in class_names:
        cnn_f1_per_class.append(cnn_report[class_name]['f1-score'])
        transfer_f1_per_class.append(transfer_report[class_name]['f1-score'])

    x_class = np.arange(len(clean_names))
    width = 0.35

    bars5 = axes[1, 0].bar(x_class - width/2, cnn_f1_per_class, width,
                           label='Working CNN', alpha=0.8, color='skyblue')
    bars6 = axes[1, 0].bar(x_class + width/2, transfer_f1_per_class, width,
                           label='Working Transfer', alpha=0.8, color='lightcoral')

    axes[1, 0].set_title('Per-Class F1-Score Performance', fontsize=14, fontweight='bold')
    axes[1, 0].set_ylabel('F1-Score')
    axes[1, 0].set_xticks(x_class)
    axes[1, 0].set_xticklabels(clean_names, rotation=45)
    axes[1, 0].legend()
    axes[1, 0].grid(axis='y', alpha=0.3)

    for bars in [bars5, bars6]:
        for bar in bars:
            height = bar.get_height()
            axes[1, 0].text(bar.get_x() + bar.get_width()/2., height + 0.01,
                           f'{height:.2f}', ha='center', va='bottom', fontweight='bold', fontsize=8)

    # Plot 4: Model Complexity vs Performance
    model_names = ['Working CNN', 'Working Transfer']
    param_counts = [working_cnn.count_params()/1e6, working_transfer.count_params()/1e6]
    accuracies = [cnn_results['accuracy'], transfer_results['accuracy']]

    colors = ['skyblue', 'lightcoral']
    for i, (name, params, acc) in enumerate(zip(model_names, param_counts, accuracies)):
        axes[1, 1].scatter(params, acc, s=200, alpha=0.7, color=colors[i], label=name)
        axes[1, 1].annotate(f'{name}\n{acc:.1%}', (params, acc),
                           xytext=(10, 10), textcoords='offset points', fontsize=10, fontweight='bold')

    axes[1, 1].set_title('Model Complexity vs Performance', fontsize=14, fontweight='bold')
    axes[1, 1].set_xlabel('Parameters (Millions)')
    axes[1, 1].set_ylabel('Accuracy')
    axes[1, 1].grid(True, alpha=0.3)
    axes[1, 1].legend()

    plt.tight_layout()
    plt.savefig('/content/drive/MyDrive/Datasets/PlantVillage/performance_comparison.png',
                dpi=300, bbox_inches='tight')
    plt.show()
    plt.close()

    return comparison_df

comparison_df = show_performance_comparison()

# =====================================================
# VISUALIZATION: SAMPLE PREDICTIONS
# =====================================================

def show_sample_predictions():
    """Generate sample_predictions.png"""
    fig, axes = plt.subplots(2, 8, figsize=(20, 10))

    sample_indices = np.random.choice(len(X_val), 8, replace=False)
    sample_images = X_val[sample_indices]
    sample_labels = y_val[sample_indices]

    cnn_predictions = working_cnn.predict(sample_images, verbose=0)
    transfer_predictions = working_transfer.predict(sample_images, verbose=0)

    clean_names = [name.split('___')[1].replace('_', ' ') for name in class_names]

    for i in range(8):
        # CNN predictions (top row)
        axes[0, i].imshow(sample_images[i])

        true_idx = np.argmax(sample_labels[i])
        cnn_pred_idx = np.argmax(cnn_predictions[i])
        cnn_confidence = np.max(cnn_predictions[i])

        true_name = clean_names[true_idx]
        cnn_pred_name = clean_names[cnn_pred_idx]

        color = 'green' if true_idx == cnn_pred_idx else 'red'
        axes[0, i].set_title(f'CNN\nTrue: {true_name}\nPred: {cnn_pred_name}\nConf: {cnn_confidence:.2f}',
                            color=color, fontsize=9, fontweight='bold')
        axes[0, i].axis('off')

        # Transfer Learning predictions (bottom row)
        axes[1, i].imshow(sample_images[i])

        transfer_pred_idx = np.argmax(transfer_predictions[i])
        transfer_confidence = np.max(transfer_predictions[i])

        transfer_pred_name = clean_names[transfer_pred_idx]

        color = 'green' if true_idx == transfer_pred_idx else 'red'
        axes[1, i].set_title(f'Transfer\nTrue: {true_name}\nPred: {transfer_pred_name}\nConf: {transfer_confidence:.2f}',
                            color=color, fontsize=9, fontweight='bold')
        axes[1, i].axis('off')

    plt.suptitle('Sample Predictions Comparison', fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.savefig('/content/drive/MyDrive/Datasets/PlantVillage/sample_predictions.png',
                dpi=300, bbox_inches='tight')
    plt.show()
    plt.close()

show_sample_predictions()

# =====================================================
# STEP 6: FINAL RESULTS AND ANALYSIS
# =====================================================

print("\n" + "="*80)
print("PLANT DISEASE DETECTION RESULTS")
print("="*80)
print(comparison_df.round(4))

# Calculate improvement
original_best = 0.3625
current_best = max(cnn_results['accuracy'], transfer_results['accuracy'])
improvement = ((current_best - original_best) / original_best) * 100

print(f"\nIMPROVEMENT ANALYSIS:")
print(f"  Original best accuracy: {original_best:.1%}")
print(f"  Current best accuracy: {current_best:.1%}")
print(f"  Improvement: {'+' if improvement > 0 else ''}{improvement:.1f}%")

if transfer_results['accuracy'] > cnn_results['accuracy']:
    winner = "Working Transfer Learning"
    winner_acc = transfer_results['accuracy']
else:
    winner = "Working CNN"
    winner_acc = cnn_results['accuracy']

print(f"  Best performing model: {winner} ({winner_acc:.1%})")

# =====================================================
# STEP 7: SAVE MODELS
# =====================================================

try:
    model_dir = '/content/drive/MyDrive/Datasets/PlantVillage/working_models'
    os.makedirs(model_dir, exist_ok=True)

    # Save CNN model
    working_cnn.save(os.path.join(model_dir, 'working_cnn_final.keras'))
    print("CNN model saved successfully!")

    # Save Transfer Learning model with compatibility settings
    transfer_model_path = os.path.join(model_dir, 'working_transfer_final.keras')

    # Method 1: Save with explicit settings
    tf.keras.models.save_model(
        working_transfer,
        transfer_model_path,
        save_format='keras',
        include_optimizer=True
    )

    print("Transfer Learning model saved successfully!")
    print(f"\nModels saved in:")
    print(f"   • Working CNN: working_cnn_final.keras")
    print(f"   • Working Transfer: working_transfer_final.keras")

except Exception as e:
    print(f"Model saving failed: {e}")

    # Fallback: Save weights only
    try:
        working_transfer.save_weights(os.path.join(model_dir, 'working_transfer_weights.weights.h5'))
        print("Transfer model weights saved as fallback")
    except Exception as e2:
        print(f"Weight saving also failed: {e2}")

# =====================================================
# FINAL SUMMARY
# =====================================================

print("\n" + "="*60)
print("PROJECT SUMMARY")
print("="*60)

print(f"\nDataset: PlantVillage tomato disease detection")
print(f"Total images: {len(X_train) + len(X_val)} (4 classes)")
print(f"Training split: {len(X_train)} images")
print(f"Validation split: {len(X_val)} images")

print(f"\nModel Results:")
print(f"Custom CNN: {cnn_results['accuracy']:.1%} accuracy")
print(f"Transfer Learning: {transfer_results['accuracy']:.1%} accuracy")

print(f"\nKey Findings:")
print(f"- Transfer learning significantly outperformed custom CNN")
print(f"- VGG16 pre-trained features work well for plant disease detection")
print(f"- Data augmentation helped prevent overfitting")
print(f"- 128x128 image size provided good balance of detail and efficiency")

print(f"\nFiles saved:")
print(f"- Model files: working_cnn_final.keras, working_transfer_final.keras")

# Check if we met the coursework requirement
if transfer_results['accuracy'] > 0.6:
    print(f"\nProject successful - exceeded 60% accuracy requirement")
else:
    print(f"\nNeed further optimization to reach 60% target")

print("="*60)

# Memory cleanup
del X, y, X_train, X_val
import gc
gc.collect()